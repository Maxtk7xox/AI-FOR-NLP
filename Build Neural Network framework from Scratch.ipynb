{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Node class\n",
    "class Node:\n",
    "    def __init__(self, inputs = []):\n",
    "        self.inputs = inputs\n",
    "        self.outputs= []\n",
    "    \n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "    \n",
    "        self.value = None\n",
    "        self.gradients = {}\n",
    "    # Key: value \n",
    "    #inputs to this node: partials of this node\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplemented\n",
    "        \n",
    "    def backward(self):\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Input class\n",
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self, value=None):\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {self:0}\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the add class\n",
    "class Add(Node):\n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "\n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the linear class\n",
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "    def backward(self):\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the sigmoid class\n",
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1./(1 + np.exp(-1 * x))\n",
    "\n",
    "    def forward(self):\n",
    "        self.x = self.inputs[0].value\n",
    "        self.value = self._sigmoid(self.x)\n",
    "\n",
    "    def backward(self):\n",
    "        self.partial = self._sigmoid(self.x) * (1 - self._sigmoid(self.x))\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self] \n",
    "            self.gradients[self.inputs[0]] = grad_cost * self.partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the mse as the loss function and define the mse class\n",
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        Node.__init__(self, [y, a])\n",
    "\n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        a = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert(y.shape == a.shape)\n",
    "        self.m = self.inputs[0].value.shape[0]\n",
    "        self.diff = y - a\n",
    "        self.value = np.mean(self.diff**2)\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(outputnode, graph):\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "\n",
    "    for n in  graph[::-1]:\n",
    "        n.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(feed_dict):\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_update(trainables, learning_rate=1e-2):\n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network\n",
    "X, y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples = 506\n"
     ]
    }
   ],
   "source": [
    "# Total number of examples\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "print(\"Total number of examples = {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 151.877\n",
      "Epoch: 101, Loss: 6.674\n",
      "Epoch: 201, Loss: 4.439\n",
      "Epoch: 301, Loss: 4.421\n",
      "Epoch: 401, Loss: 4.814\n",
      "Epoch: 501, Loss: 3.898\n",
      "Epoch: 601, Loss: 3.833\n",
      "Epoch: 701, Loss: 4.835\n",
      "Epoch: 801, Loss: 4.032\n",
      "Epoch: 901, Loss: 3.921\n",
      "Epoch: 1001, Loss: 2.949\n",
      "Epoch: 1101, Loss: 3.498\n",
      "Epoch: 1201, Loss: 3.385\n",
      "Epoch: 1301, Loss: 3.343\n",
      "Epoch: 1401, Loss: 3.655\n",
      "Epoch: 1501, Loss: 3.621\n",
      "Epoch: 1601, Loss: 3.487\n",
      "Epoch: 1701, Loss: 3.031\n",
      "Epoch: 1801, Loss: 3.167\n",
      "Epoch: 1901, Loss: 3.202\n",
      "Epoch: 2001, Loss: 2.881\n",
      "Epoch: 2101, Loss: 2.911\n",
      "Epoch: 2201, Loss: 2.931\n",
      "Epoch: 2301, Loss: 2.922\n",
      "Epoch: 2401, Loss: 3.278\n",
      "Epoch: 2501, Loss: 2.990\n",
      "Epoch: 2601, Loss: 3.543\n",
      "Epoch: 2701, Loss: 3.323\n",
      "Epoch: 2801, Loss: 3.200\n",
      "Epoch: 2901, Loss: 3.016\n",
      "Epoch: 3001, Loss: 2.965\n",
      "Epoch: 3101, Loss: 3.331\n",
      "Epoch: 3201, Loss: 2.734\n",
      "Epoch: 3301, Loss: 3.226\n",
      "Epoch: 3401, Loss: 2.948\n",
      "Epoch: 3501, Loss: 2.743\n",
      "Epoch: 3601, Loss: 3.401\n",
      "Epoch: 3701, Loss: 3.216\n",
      "Epoch: 3801, Loss: 2.866\n",
      "Epoch: 3901, Loss: 2.719\n",
      "Epoch: 4001, Loss: 3.350\n",
      "Epoch: 4101, Loss: 2.838\n",
      "Epoch: 4201, Loss: 2.811\n",
      "Epoch: 4301, Loss: 2.676\n",
      "Epoch: 4401, Loss: 2.920\n",
      "Epoch: 4501, Loss: 2.932\n",
      "Epoch: 4601, Loss: 3.244\n",
      "Epoch: 4701, Loss: 3.121\n",
      "Epoch: 4801, Loss: 3.214\n",
      "Epoch: 4901, Loss: 3.380\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # Step 1\n",
    "        # Randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "\n",
    "        # Reset value of X and y Inputs\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "\n",
    "        # Step 2\n",
    "        _ = None\n",
    "        forward_and_backward(_, graph)\n",
    "\n",
    "        # Step 3\n",
    "        rate = 1e-2    \n",
    "        sgd_update(trainables, rate)\n",
    "        loss += graph[-1].value\n",
    "    \n",
    "    if i % 100 == 0: \n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11bf82d68>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGdtJREFUeJzt3WuMZOV95/Hv/1yqqrvn0nNpYJiZZVh7vAtEAWdHhMh+4YUEY8cKvDASVjYZZZF4w64cJSuvnTcoTpBsrWS8ltbRIoNMoiQYOcmCLEvOiEuSXSngJlwMTIDhPszANPR0T09f6vrfF+ep6uruqu6eoS/DOb+PVKqqp07VPM9Udf3O/zzn1DF3R0REiifa7A6IiMjmUACIiBSUAkBEpKAUACIiBaUAEBEpKAWAiEhBKQBERApKASAiUlAKABGRgko2uwPL2b17tx84cGCzuyEi8rHy9NNPf+DuIystd0EHwIEDBxgdHd3sboiIfKyY2VurWU6bgERECkoBICJSUAoAEZGCUgCIiBSUAkBEpKAUACIiBaUAEBEpqFwGwMnJWb7z9y/z+tjZze6KiMgFK5cBMDZV5XuPHeP1senN7oqIyAUrlwFQSWMAqo3WJvdEROTClcsAKCfZsObqzU3uiYjIhSunAaAKQERkJbkMgEqaDavaUAUgItJPLgNAFYCIyMpyGQAlzQGIiKwolwEQR0YamyoAEZFl5DIAACpJTLWuABAR6Se3AVBOI+Y0CSwi0ld+A0AVgIjIsnIcAJF2AxURWUZ+AyCNNQksIrKM/AZAEmk3UBGRZeQ6AFQBiIj0l98A0CYgEZFl5TYAKklEVZuARET6ym0AqAIQEVlefgNAFYCIyLLyHQCqAERE+sptAFS0CUhEZFm5DQAdByAisrwcB0BMo+U0mqoCRER6yW0AtE8LWVMAiIj0lNsAKIezgukXQUVEestvAKTZeYF1TgARkd7yGwCqAERElrXqADCz2MyeMbOfhPuXm9mTZvaqmf3IzEqhvRzuHwuPH+h6jW+E9pfN7PNrPZhulVABaFdQEZHezqUC+CpwtOv+t4F73P0gcBq4PbTfDpx2908C94TlMLMrgduAq4CbgO+bWfzRut9fuwLQrqAiIr2tKgDMbB/wm8APwn0Drgd+HBZ5ALgl3L453Cc8fkNY/mbgQXevuvsbwDHg2rUYRC/lRBWAiMhyVlsBfBf4GtD+Nt0FTLh7I9w/DuwNt/cC7wCExyfD8p32Hs9Zc+WwG6hOCyki0tuKAWBmXwJOufvT3c09FvUVHlvuOd3/3h1mNmpmo2NjYyt1r69KuwLQJLCISE+rqQA+A/yWmb0JPEi26ee7wLCZJWGZfcCJcPs4sB8gPL4dGO9u7/GcDne/190PufuhkZGRcx5QW7sC0G6gIiK9rRgA7v4Nd9/n7gfIJnEfc/ffBh4HvhwWOww8HG4/Eu4THn/M3T203xb2ErocOAg8tWYjWUS7gYqILC9ZeZG+/jvwoJn9KfAMcF9ovw/4CzM7RrbmfxuAu79oZg8BLwEN4E53X7fVc00Ci4gs75wCwN2fAJ4It1+nx1487j4H3Nrn+XcDd59rJ89HRZPAIiLLyvGRwOGnILQJSESkpxwHgCoAEZHl5DYAosgoxTotpIhIP7kNAGifGF4BICLSS74DII10HICISB/5DoAkVgUgItJHvgMgjTQJLCLSR74DIIk1CSwi0kfOAyDS+QBERPrIfQCoAhAR6S3XAVBJtQlIRKSfXAdAdhyANgGJiPSS7wBQBSAi0le+A0AVgIhIX7kOgEqqSWARkX5yHQDlJNZuoCIifeQ8AFQBiIj0k/MAiGm0nEZTISAisliuA6B9WsiaAkBEZIlcB0D7rGA6LaSIyFL5DoA0Oy+wfhFURGSpXAdAexOQzgkgIrJUrgOgnLQrAAWAiMhiOQ+A9hyANgGJiCyW8wBQBSAi0k+uA6AzB6BJYBGRJXIdAJ0KQJPAIiJL5DsAQgUwpwpARGSJfAdAot1ARUT6yXUAVFJNAouI9JPrAOhUANoEJCKyRM4DIKsA9FtAIiJL5TwAVAGIiPST6wCIIqMU66QwIiK9rBgAZlYxs6fM7Dkze9HM/ji0X25mT5rZq2b2IzMrhfZyuH8sPH6g67W+EdpfNrPPr9egupWTSD8FISLSw2oqgCpwvbtfDVwD3GRm1wHfBu5x94PAaeD2sPztwGl3/yRwT1gOM7sSuA24CrgJ+L6ZxWs5mF7KOjG8iEhPKwaAZ86Gu2m4OHA98OPQ/gBwS7h9c7hPePwGM7PQ/qC7V939DeAYcO2ajGIZ5STWcQAiIj2sag7AzGIzexY4BRwBXgMm3L0RFjkO7A239wLvAITHJ4Fd3e09ntP9b91hZqNmNjo2NnbuI1okqwC0CUhEZLFVBYC7N939GmAf2Vr7Fb0WC9fW57F+7Yv/rXvd/ZC7HxoZGVlN95ZVTmLtBioi0sM57QXk7hPAE8B1wLCZJeGhfcCJcPs4sB8gPL4dGO9u7/GcdVNOVAGIiPSymr2ARsxsONweAH4dOAo8Dnw5LHYYeDjcfiTcJzz+mLt7aL8t7CV0OXAQeGqtBtJPRZPAIiI9JSsvwh7ggbDHTgQ85O4/MbOXgAfN7E+BZ4D7wvL3AX9hZsfI1vxvA3D3F83sIeAloAHc6e7rvmpeTmImZuvr/c+IiHzsrBgA7v488Oke7a/TYy8ed58Dbu3zWncDd597N89fOYmo6jgAEZElcn0kMEA5jbUJSESkh9wHQEUVgIhIT7kPAB0JLCLSW/4DIIn1W0AiIj0UIABUAYiI9JL7AKikMY2W02gqBEREuuU+ANonhakpAEREFihMAOj3gEREFsp/AKTZKQf0e0AiIgvlPgAqaTgvsCoAEZEFch8A5SSrAOZUAYiILFCAAFAFICLSS+4DoNKZA1AAiIh0y30AdCoAbQISEVmgAAEQ5gC0CUhEZIH8B0CqCkBEpJfcB0AlVACaBBYRWSj3ATBfASgARES65T8AOj8FoU1AIiLdChAA2g1URKSXAgSAJoFFRHrJfQBEkVGKdVIYEZHFch8AkFUBmgMQEVmoGAGgE8OLiCxRjABIYh0HICKySDECII00CSwiskgxAiCJ9VtAIiKLFCQAVAGIiCxWiACoaBJYRGSJQgRANgmsCkBEpFtBAkAVgIjIYoUIgEoaKwBERBYpRACUk0ibgEREFlkxAMxsv5k9bmZHzexFM/tqaN9pZkfM7NVwvSO0m5l9z8yOmdnzZvYrXa91OCz/qpkdXr9hLVROI+ZUAYiILLCaCqAB/KG7XwFcB9xpZlcCXwcedfeDwKPhPsAXgIPhcgfwZ5AFBnAX8KvAtcBd7dBYb5oEFhFZasUAcPeT7v4v4fYUcBTYC9wMPBAWewC4Jdy+Gfhzz/wzMGxme4DPA0fcfdzdTwNHgJvWdDR9aDdQEZGlzmkOwMwOAJ8GngQudveTkIUEcFFYbC/wTtfTjoe2fu3rrpzENFpOo6kQEBFpW3UAmNkW4G+A33f3M8st2qPNl2lf/O/cYWajZjY6Nja22u4ta/6kMAoAEZG2VQWAmaVkX/5/6e5/G5rfD5t2CNenQvtxYH/X0/cBJ5ZpX8Dd73X3Q+5+aGRk5FzG0pcCQERkqdXsBWTAfcBRd/9O10OPAO09eQ4DD3e1/27YG+g6YDJsIvoZcKOZ7QiTvzeGtnVXSdvnBdZEsIhIW7KKZT4D/A7wCzN7NrT9EfAt4CEzux14G7g1PPZT4IvAMWAG+D0Adx83sz8Bfh6W+6a7j6/JKFZQTkMFoF8EFRHpWDEA3P3/0nv7PcANPZZ34M4+r3U/cP+5dHAtlJOsAphTBSAi0lGYI4FBFYCISLdCBMD8HIACQESkrRABML8XkDYBiYi0FSQAwhyANgGJiHQUIwBSVQAiIosVIgAqoQLQJLCIyLxCBEC7AtBuoCIi84oRANoNVERkiUIEgHYDFRFZqhABUIo1CSwislghAiCKjFIcaTdQEZEuhQgACCeGVwUgItJRnABIY80BiIh0KU4AJJH2AhIR6VKcAEgjHQcgItKlOAGQxKoARES6FCYAKqkmgUVEuhUmALK9gFQBiIi0FSgAYqp1VQAiIm0FCgBVACIi3QoTABUdByAiskBhAiA7DkCbgERE2ooTAGnEnCoAEZGO4gSAJoFFRBYoTABkxwGoAhARaStMAJSTmEbLaTQVAiIiUKgAaJ8URgEgIgIFCgCdFlJEZKHCBMB8BaCJYBERKFIApNlQdVpIEZFMcQIgaW8CUgUgIgIFCoBKqAB0TgARkUxhAmC+AlAAiIhAoQKgPQegTUAiIrCKADCz+83slJm90NW208yOmNmr4XpHaDcz+56ZHTOz583sV7qeczgs/6qZHV6f4fSnCkBEZKHVVAA/BG5a1PZ14FF3Pwg8Gu4DfAE4GC53AH8GWWAAdwG/ClwL3NUOjY3SmQPQJLCICLCKAHD3fwTGFzXfDDwQbj8A3NLV/uee+Wdg2Mz2AJ8Hjrj7uLufBo6wNFTWVacC0CSwiAhw/nMAF7v7SYBwfVFo3wu807Xc8dDWr33DdI4DUAUgIgKs/SSw9WjzZdqXvoDZHWY2amajY2Nja9axzpHAqgBERIDzD4D3w6YdwvWp0H4c2N+13D7gxDLtS7j7ve5+yN0PjYyMnGf3ltJvAYmILHS+AfAI0N6T5zDwcFf774a9ga4DJsMmop8BN5rZjjD5e2No2zClWJPAIiLdkpUWMLO/Bj4H7Daz42R783wLeMjMbgfeBm4Ni/8U+CJwDJgBfg/A3cfN7E+An4flvunuiyeW11UUGaU40m8BiYgEKwaAu3+lz0M39FjWgTv7vM79wP3n1Ls1Vk4jVQAiIkFhjgSGcF5gzQGIiACFC4BIPwUhIhIUKwB0YngRkY5CBUAliXUcgIhIUKgA0CSwiMi8YgVAEqkCEBEJChYAsSoAEZGgUAFQ0SSwiEhHoQJAxwGIiMwrWADoOAARkbZiBYA2AYmIdBQqALLjAFQBiIhAwQJAFYCIyLxiBUAS02g5jaZCQESkYAHQPimMAkBEpFABoNNCiojMK1QAzFcAmggWESlWAKTZcHVaSBGRggVAJWlvAlIFICJSqABoVwD6RVARkaIFQKJJYBGRtoIFQHsOQJuAREQKFQDaDVREZF6hAkC7gYqIzCtYAGQVgHYDFREpWgCkqgBERNoKFQCd4wBUAYiIFCsA5isABYCISKECoBRHJJHxV0+9xUOj71BTEIhIgRUqAKLI+N+/8x/YVkn52o+f53P/43F++P/eYLamOQERKR5z983uQ1+HDh3y0dHRNX9dd+cfXhnj+4+/xlNvjrNrqMR//uzl3HDFRURmGGAGYJhBrdFifLrGh9M1PjxbZXy6xgdna1TrTQ5evJVf2ruNqy7dzs6h0qr70Gw5r56a4tm3J3ju+AS1hvPvLtnCpy7eyqcu3sqe7RUs64SIyDkxs6fd/dCKyxUxALo99cY433/iGE+8PLbq50QGO4dKpHHEycm5Tvve4QGuunQbV+zZxtZKQhwZSWRE4dowXvvgLM++PcEv3p1kJlQe2yoJ5TRmbKraea2t5YRPXbKVy3YOUk4j0nj+UoqNgVLCv9+zlav3DZ9T8HwUzZYzNVdnaq4BZCEZmYULmBmlOKKUZJc4UoCJbAYFwDn61/fO8NqpaRzHHZysUgBI44idQyV2bymxc6jM8EBKFL7cJmZqvHTiDC+cmOSFd7PrNz6Ypt9/axobV+7ZxjX7h7l6/zDX7B/m8t1DmBmnp2u88v4Ur5w6yyvvTfHy+1OcmJil1mhRb7aoN51as7Vk7mL/zgF+ed8wV+/bzlWXbme21uTE5CzvTsxyYmKOExOznJiYpd5szYdIMh8mcZRdLHyRR5bdb7acydl659L+4l+tJDJKSUQ5idg2kHLR1jIXba0wsrXMRduy21vKMdVGNqbu63qzRcudlmfvQ8vn35ct5YThwZTtAynDA6XO7TgyHGi12stmz28/lwXv7cK+tostAxotZ2KmzsRMjdMzdU7P1Dg9XWNytk4ljdk2kLCtkrK1krJtIGFrJWVqrs6JiVnePT3Lu+3/88lZZmtNhsoJg6WYoVLCYDm7rqQx5RCUpa73o5xGDKQxA2lMpRTP306jzvsUW7ZSkb1PMFNrMj6d9XF8ph6uaxiwb8cg+3YMsH/nIPt3DHDp8ACVNGam1uC9yTneOzPH+2fmeG+yyvh0lUoas7WSjSkbY8LWStIZw2Apuy4nEWZGrdHindMzvPXhNG9+EK4/nGFytp71vdTuf8xAKWKolLB9MGXHYIkdgynDgyV2DGbv4UB43VIcLah+G80WJyfneHt8hrc+nOHt8RneHp+m2XL2bB/gku0V9myvcMm2Cnu2D7BzSylbIQkVfPeKykorJe7OXL3F2WqD6WqDRqvV+czQ9bmZqzcX/G20L7O1Zufvq/3ZT2MjjSOaLafedOrNFo1mi3o4PW210WKu3mS2nl3P1ZtU6y2u+8Qu/uA3PnVOf3Pzn2cFwKaZqzepNVu0Wk6j5TS7LiNby52fpDhf7s5UtcGL757hueMTPH98gufemeTdidkFy5XiiD3DFS7dPsCe4QoDaUw9BEg7TLIPo4cv2/CF2cpuR2ZsG8i+XLcPpGwbSBkeSNlSSYjMwhfr/Jdsq+XUmk6t80Xe7HyhT87WOTU1x6mpKmNnqkxVVx8m7VAyy/4AG62N/8wOpDHbB1KqjSZn5ho0+/Rhazlhb/iivXS4wmApYabWYKbaZLrWYKbWZLqaXdebrU6gdy4h6M+XGQwPpOwYKtFqOScm5qgtOgf2UClmuse8VyWNqDZafVdeukWW/Z/M1pt0/1dsKSdctmuQnUMlqvUWs/VmdqllX2xnq41V7YVXDl+epSRmYqa24D0vxRH7dg4Qm/HemblzWjGJo/kqtTuA5+pNpsL70u+9XU2fB0tx9rcV3svlpLGRRFnoV5Is5CtpTDmNqSQRn/3kbv7rDQfPqy+rDYDkvF79IzCzm4D/CcTAD9z9Wxvdh/VWCWs868XM2FZJ+bVP7OLXPrGr0/7h2SpHT06xpZJw6XCF3UPlTqVyoZmtNTk1Ncd0tdn5Yyx31ppi0ni+KlmsvfY1MVMP19naecu9a62vvVkqCw/I2trzO+3lYH6tzsN6XmTG8EC2drpzKFs77X4/3Z2ZWpOpuQZn5upMzdUZKidcOjzAtkr6kf9vGs0Wc41W50uz/QXaCMHcDNetFjTdGSzF7Ah9bVdCba2W8/7UHMdPz/LO+AzHT89yeqbGyNYyl2zL1povDmvPQ+WEVsuZrjWYmmssGN90NevDTK3BdK19u8mWcsyB3UNctmuIA+GLf6W5q9laM6uqZmpMhAprYqaerfmGFYZqI1sLrjZa7BxKuWznEPt3DnLZrkEu3lZZMMaz1VDNTM5xcjIbX1Y5Zism7fes2YJas7mg2qw1WlSbLQbSmC3lhKFyzJZyypZyzFA5IY2z/WTan5n27VIcsX1wfuVo+0C65G/e3edXtBot4thIo2jZz/ZG29AKwMxi4BXgN4DjwM+Br7j7S72W/7hWACIim2m1FcBG7wZ6LXDM3V939xrwIHDzBvdBRETY+ADYC7zTdf94aOswszvMbNTMRsfGVr9njoiInJuNDoBeG70WbINy93vd/ZC7HxoZGdmgbomIFM9GB8BxYH/X/X3AiQ3ug4iIsPEB8HPgoJldbmYl4DbgkQ3ug4iIsMG7gbp7w8z+C/Azst1A73f3FzeyDyIiktnw4wDc/afATzf63xURkYUK9WugIiIy74L+KQgzGwPe+ggvsRv4YI2683GicReLxl0sqxn3Ze6+4m6UF3QAfFRmNrqao+HyRuMuFo27WNZy3NoEJCJSUAoAEZGCynsA3LvZHdgkGnexaNzFsmbjzvUcgIiI9Jf3CkBERPrIZQCY2U1m9rKZHTOzr292f9aLmd1vZqfM7IWutp1mdsTMXg3XOzazj+vBzPab2eNmdtTMXjSzr4b2XI/dzCpm9pSZPRfG/ceh/XIzezKM+0fhZ1Zyx8xiM3vGzH4S7hdl3G+a2S/M7FkzGw1ta/JZz10AhJPO/C/gC8CVwFfM7MrN7dW6+SFw06K2rwOPuvtB4NFwP28awB+6+xXAdcCd4T3O+9irwPXufjVwDXCTmV0HfBu4J4z7NHD7JvZxPX0VONp1vyjjBviP7n5N1+6fa/JZz10AUKCTzrj7PwLji5pvBh4Itx8AbtnQTm0Adz/p7v8Sbk+RfSnsJedj98zZcDcNFweuB34c2nM3bgAz2wf8JvCDcN8owLiXsSaf9TwGwIonncm5i939JGRflMBFm9yfdWVmB4BPA09SgLGHzSDPAqeAI8BrwIS7t8+MntfP+3eBrwHtM63vohjjhizk/97MnjazO0LbmnzWN/zH4DbAiiedkXwwsy3A3wC/7+5nLoSTbK83d28C15jZMPB3wBW9FtvYXq0vM/sScMrdnzazz7Wbeyyaq3F3+Yy7nzCzi4AjZvava/XCeawAin7SmffNbA9AuD61yf1ZF2aWkn35/6W7/21oLsTYAdx9AniCbA5k2MzaK3N5/Lx/BvgtM3uTbJPu9WQVQd7HDYC7nwjXp8hC/1rW6LOexwAo+klnHgEOh9uHgYc3sS/rImz/vQ846u7f6Xoo12M3s5Gw5o+ZDQC/Tjb/8Tjw5bBY7sbt7t9w933ufoDs7/kxd/9tcj5uADMbMrOt7dvAjcALrNFnPZcHgpnZF8nWENonnbl7k7u0Lszsr4HPkf064PvAXcD/AR4C/g3wNnCruy+eKP5YM7PPAv8E/IL5bcJ/RDYPkNuxm9kvk034xWQrbw+5+zfN7N+SrRnvBJ4B/pO7Vzevp+snbAL6b+7+pSKMO4zx78LdBPgrd7/bzHaxBp/1XAaAiIisLI+bgEREZBUUACIiBaUAEBEpKAWAiEhBKQBERApKASAiUlAKABGRglIAiIgU1P8HsTo7BOsxnMMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
